## ETL 工具 kettle 学习笔记1

1. 使用场景，交换同步数据，迁移数据（从 DB2 到 MySQL）

2. 有两个文件。

   - 转化（**transformation**）


   - 作业（ **job** ）

   都是使用组件（图形化）完成 ETL 转化。

   - [ ] 转化有两个对象，一个是核心对象树，一个是主对象树。

   - [ ] 主对象是用来配置转化参数，核心对象是用组件来完成相关操作。

         ​

3.主对象树有四颗叶子树节点构成，分别是：

- DB连接：显示当前transformation中的数据库连接，每一个–transformation的数据库连接都需要单独配置；这也是缺点。


- Steps：一个transformation中应用到的环节列表步骤。
- Hops：一个transformation中应用到的节点连接列表。

4.核心对象是许多组件，也是重要的工具，包含大部分数据操作，分别有：

- Input：输入环节 

- Output：输出环节

- Lookup：查询环节

- Transform：转化环节

- Joins：连接环节

- Scripting：脚本环节

  输入输出环节实现数据传输，其他的环节都是操作函数 已经是用Java封装好的图形化组件，可以直接使用。想熟练使用该工具就是好好使用这些这些这件，并且能快速的找到该组建的使用场景，解决数据转化中出现的各种问题。

  比如，我昨天从DB2向MySQL数据导表结构数据，其中DB2源端的编码方式我不知道，我需要配置编码方式。建表过程已经约束了，还是不行，数据表删除了重新来还是不行，最后得知我们的服务都扑在Windows下，源端数据在Linux系统下，也不能修改编码方式，导致转化错误。

  ​

缺点：

- 要配置内存，执行效率低。

- 日志报错流也不容易找到。

- 每次转化只能定义一个流程，反复配置太麻烦了。

- 另外配置数据库的时候要相关驱动。

  ​

假如有多个表更新插入操作，都是从同一源端到目的端。流程执行顺序也是没有的，想要控制的话就要写job定时任务。这样处理多表外键关联批量操作会出现问题。通过job串起来，保证执行任务还要写定时任务。job就是transformation的补充。

由于是Java开发的，所以配置之前都要装 JDK，才能运行。

